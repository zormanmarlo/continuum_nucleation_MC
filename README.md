# Monte Carlo Model for Simulation of Ion Speciation

## Overview
A Monte Carlo code that simulates speciation and nucleation of ions in a continuous coordinate space. Ions are represented as spherical particles. Interactions are calculated based on a user-supplied set of tabulated potentials, which should be placed in the potentials/ directory.

Note that this framework begins to fail at high concentrations/large cluster sizes, as the singular set of potentials is likely to inadequately represent particle interactions in denser environments. 
 
## Files and Classes

- `simulation.py`: Main simulation driver class, handles I/O and parallelization
- `system.py`: Physics implementation and Monte Carlo engine, handles particle positions, types, clusters, etc
- `config.py`: Configuration file parser and validation

**utils.py**
- `PMF`: Potential of mean force class for tabulated interactions
  - Loads and interpolates energy data from files
  - Supports different interaction types (ion-ion, cation-anion)
- `Bias`: Umbrella sampling bias potential implementation
  - Supports harmonic and linear bias types
  - Handles adaptive bias updates for enhanced sampling
- Numba-compiled functions: `calc_energy_numba()`, `find_neighbors_numba()`, `interpolate_energy_numba()`

**moves.py**
- `Move`: Base class for Monte Carlo moves with statistics tracking
- `TranslationMove`: Random particle displacement within spherical constraint
- `SwapMove`: Random particle repositioning anywhere in box
- `InOutAVBMCMove`/`OutInAVBMCMove`: Aggregation-Volume-Bias Monte Carlo moves
- `NVTInOutMove`/`NVTOutInMove`: Nucleation moves with Rosenbluth sampling

## Simple example

Run a basic NaCl nucleation simulation:

```bash
# Run a short test simulation (single processor)
python simulation.py -config configs/test_config.txt -jobname test_run

# Run with multiple processors for better statistics
python simulation.py -np 4 -config configs/test_config.txt -jobname parallel_test

# Run with custom output directory
python simulation.py -config configs/test_config.txt -jobname my_sim -path ./results
```

**Output Files Generated:**
- `E-XX.log`: Energy vs time trajectories
- `traj-XX.xyz`: Particle coordinates
- `clusters-XX.out`: Cluster size distributions over time
- `target_cluster-XX.out`: Size of cluster around particle 0
- `stats-XX.log`: Monte Carlo move acceptance rates

## Umbrella sampling example
Umbrella sampling along the nuclei size can be performed by running a set of biased simulations with increasing bias centers. See the directory _US_files_ for the following files:
- _run_us.sh_ is a basic US driver. It iterates over the range of cluster size centers and generates an edited config input and slurm submission file that it then submits and deletes.
- _submit_template.sh_ is the template slurm submission file that is edited by _run_us.sh_
- _configs/nacl_us/100mM_nacl_template_large_random_JC.txt_ is an example of a template submission script that is copied and edited by _run_us.sh_. Note that this one is set up for a 100 mM NaCl system with the JC forcefield. The two important pieces in this file are the bias center and the coordinate input path, both of which are edited for each window by _run_us.sh_
- _inputs/nacl_us/100mM_nacl_32mer_large_random_00.xyz_ is an example of window coordinate inputs.
- _gen_US_structs.py_ is a script to generate NaCl cluster inputs for US windows. For each input it generates a (randomly populated) cluster of size N, as well as randomly placed bath atoms. Note that the central cluster is generated by randomly growing a cluster of size N with neighbors from a lattice. Bath atoms are placed such that they are not in the central custer.

IMPORTANT NOTE: As of right now, I run five independent simulations for each US window. Whenever a job for a window is run, it launches five independent simulations. Each simulation needs it own input structure. that is why input xyz files have the _00_, _01_, etc at the end. In order to not have 5\*N_windows config files, we omit the ID in the template config files. When a simulation is launched and told to use an input file, it adds its ID to the end of the xyz file.

So, in order to run an US simulation, do the following:
1. Generate input structures with _gen_US_structs.py_. This code is unoptimized and may take some time to run for higher concentrations. Edit the parameters within it to get the number of input structures per window you concentration you prefer.
2. Create a config template with the parameters you would like
3. Edit a _submit_template.sh_ to work for your cluster
4. Run your windows, make sure to use _-multi_ flag to indicate that each markov chain has it's own input file
5. Once all windows are run, you can combine the colvar files from independent trajectories for each window with _clean_colvars.sh_. By default we delete the first half of each trajectory. 
6. Run WHAM on the resulting colvar files. 

## Adaptive US example
Adaptive US is as easy as running _simulation.py_ with the _-adaptive_ flag. Note that when you do this, all independent processes will run for the number of steps in the config file in each adaptive iteration before clustering data is collected and the bias is updated. 
